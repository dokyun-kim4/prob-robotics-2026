{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55a6e48f",
   "metadata": {},
   "source": [
    "# Day Activities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caf6eb9",
   "metadata": {},
   "source": [
    "## Problem 1: Exercise problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce3e767b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior t=1:\n",
      "[[0.94258373]\n",
      " [0.05741627]]\n",
      "Posterior t=2:\n",
      "[[0.80408163]\n",
      " [0.19591837]]\n",
      "Posterior t=3:\n",
      "[[0.50642674]\n",
      " [0.49357326]]\n",
      "Posterior t=4:\n",
      "[[0.20414508]\n",
      " [0.79585492]]\n",
      "Posterior t=5:\n",
      "[[0.06026308]\n",
      " [0.93973692]]\n",
      "Posterior t=6:\n",
      "[[0.01577893]\n",
      " [0.98422107]]\n",
      "Posterior t=7:\n",
      "[[0.00399198]\n",
      " [0.99600802]]\n",
      "Posterior t=8:\n",
      "[[0.00100099]\n",
      " [0.99899901]]\n",
      "Posterior t=9:\n",
      "[[2.50435720e-04]\n",
      " [9.99749564e-01]]\n",
      "Posterior t=10:\n",
      "[[6.26206918e-05]\n",
      " [9.99937379e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "LIKELIHOOD = np.array([\n",
    "                        [0.25],\n",
    "                        [1],\n",
    "                       ])\n",
    "\n",
    "def bayes_filter(prior: np.ndarray):\n",
    "    numerator = LIKELIHOOD * prior\n",
    "    normalizer = np.sum(numerator)\n",
    "    return numerator / normalizer\n",
    "\n",
    "# Bayes loop from N = 1,2,...,10\n",
    "\n",
    "# Initialize prior = [nf ; f] <- column vector\n",
    "prior = np.array([\n",
    "                [0.985],\n",
    "                [0.015]\n",
    "                ])\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Posterior t={i+1}:\")\n",
    "    pxz = bayes_filter(prior)\n",
    "    print(pxz)\n",
    "    # update prior\n",
    "    prior = pxz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fd2718",
   "metadata": {},
   "source": [
    "### Exercise 2: Robot Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c48b0d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "TRANSITION_MAT = np.array([[0, 0, 0],\n",
    "                           [0.5, 0.8, 0.3],\n",
    "                           [0.5, 0.2, 0.7]])\n",
    "\n",
    "SENSOR_MAT = np.array([[0, 0.5, 0.5],\n",
    "                       [0, 0.9, 0.1],\n",
    "                       [0, 0.1, 0.9]])\n",
    "\n",
    "class State(Enum):\n",
    "    ROOM1 = 0\n",
    "    ROOM2 = 1\n",
    "    ROOM3 = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35f7c2",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "In one version of the game, the tagged robot shuts down for a few seconds to give the other robot a chance to run away. Our “it” robot just wakes up after some set time, and would like to estimate where the other robot is in the world. After one world timestep, what is the probability distribution over where the other robot is? Over two timesteps? Continue computing a prediction further into the future – what do you notice about the distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2832a478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction at t = 0: prior =array([[1., 0., 0.]])\n",
      "Prediction at t = 1: prior =array([[0. , 0.5, 0.5]])\n",
      "Prediction at t = 2: prior =array([[0.  , 0.55, 0.45]])\n",
      "Prediction at t = 3: prior =array([[0.   , 0.575, 0.425]])\n",
      "Prediction at t = 4: prior =array([[0.    , 0.5875, 0.4125]])\n",
      "Prediction at t = 5: prior =array([[0.     , 0.59375, 0.40625]])\n",
      "Prediction at t = 6: prior =array([[0.      , 0.596875, 0.403125]])\n",
      "Prediction at t = 7: prior =array([[0.       , 0.5984375, 0.4015625]])\n",
      "Prediction at t = 8: prior =array([[0.        , 0.59921875, 0.40078125]])\n",
      "Prediction at t = 9: prior =array([[0.        , 0.59960938, 0.40039062]])\n",
      "Prediction at t = 10: prior =array([[0.        , 0.59980469, 0.40019531]])\n",
      "Prediction at t = 11: prior =array([[0.        , 0.59990234, 0.40009766]])\n",
      "Prediction at t = 12: prior =array([[0.        , 0.59995117, 0.40004883]])\n",
      "Prediction at t = 13: prior =array([[0.        , 0.59997559, 0.40002441]])\n",
      "Prediction at t = 14: prior =array([[0.        , 0.59998779, 0.40001221]])\n",
      "Prediction at t = 15: prior =array([[0.       , 0.5999939, 0.4000061]])\n",
      "Prediction at t = 16: prior =array([[0.        , 0.59999695, 0.40000305]])\n",
      "Prediction at t = 17: prior =array([[0.        , 0.59999847, 0.40000153]])\n",
      "Prediction at t = 18: prior =array([[0.        , 0.59999924, 0.40000076]])\n",
      "Prediction at t = 19: prior =array([[0.        , 0.59999962, 0.40000038]])\n",
      "Prediction at t = 20: prior =array([[0.        , 0.59999981, 0.40000019]])\n",
      "Prediction at t = 21: prior =array([[0.       , 0.5999999, 0.4000001]])\n",
      "Prediction at t = 22: prior =array([[0.        , 0.59999995, 0.40000005]])\n",
      "Prediction at t = 23: prior =array([[0.        , 0.59999998, 0.40000002]])\n",
      "Prediction at t = 24: prior =array([[0.        , 0.59999999, 0.40000001]])\n",
      "Prediction at t = 25: prior =array([[0.        , 0.59999999, 0.40000001]])\n",
      "Prediction at t = 26: prior =array([[0. , 0.6, 0.4]])\n",
      "Prediction at t = 27: prior =array([[0. , 0.6, 0.4]])\n",
      "Prediction at t = 28: prior =array([[0. , 0.6, 0.4]])\n",
      "Prediction at t = 29: prior =array([[0. , 0.6, 0.4]])\n",
      "Prediction at t = 30: prior =array([[0. , 0.6, 0.4]])\n"
     ]
    }
   ],
   "source": [
    "prior = np.array([[1.0, 0.0, 0.0]])\n",
    "print(f\"Prediction at t = 0: {prior =}\")\n",
    "for i in range(30):\n",
    "    prior@=TRANSITION_MAT.T\n",
    "    print(f\"Prediction at t = {i+1}: {prior =}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aca1525",
   "metadata": {},
   "source": [
    "We see that the prediction converges to [0, 0.6, 0.4] starting from t = 26. Since we have no observations, the distribution converges to the bias present in the transition matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c72e4d1",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "In another version of the game, there is no shutdown period, but our “it” robot can only take noisy measurements (model in the table below) of where the other robot is according to a measurement model. While our “it” robot is still certain that the other robot started in Room 1, over the next 5 timesteps it observes the other robot in {Room 2, Room 3, Room 3, Room 2, Room 3}. Using filtering, what is the point-wise most likely trajectory of the chased robot? Using smoothing, what is the most likely trajectory of the chased robot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25c2fe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FORWARD STEP ---\n",
      "Forward step k = 1: [0.5 0.  0. ]\n",
      "Forward step k = 2: [0.    0.025 0.225]\n",
      "Forward step k = 3: [0.      0.00875 0.14625]\n",
      "Forward step k = 4: [0.        0.0457875 0.0104125]\n",
      "Forward step k = 5: [0.         0.00397538 0.01480163]\n",
      "\n",
      "--- FILTERED STEP ---\n",
      "Filtered estimate k = 1: [1. 0. 0.]\n",
      "Filtered estimate k = 2: [0.  0.1 0.9]\n",
      "Filtered estimate k = 3: [0.         0.05645161 0.94354839]\n",
      "Filtered estimate k = 4: [0.        0.8147242 0.1852758]\n",
      "Filtered estimate k = 5: [0.         0.21171513 0.78828487]\n"
     ]
    }
   ],
   "source": [
    "def forward_step(alpha_k: np.ndarray, Mmat: np.ndarray, Tmat: np.ndarray, z_kplus1: State):\n",
    "    \"\"\"\n",
    "    Referenced from implementation example\n",
    "\n",
    "    alpha_k: forward step result from prior step; 1x3 row vector\n",
    "    Mmat: measurement model matrix; 3x3\n",
    "    Tmat: transition model matrix; 3x3\n",
    "    z_kplus1: new observation about robot state; State Enum\n",
    "    \"\"\"\n",
    "    alpha_temp = np.zeros_like(alpha_k)\n",
    "    # Sum up all possible transition from previous state; alpha_k * T_qs\n",
    "    for room in State:\n",
    "        alpha_temp += alpha_k[room.value] * Tmat[:,room.value]\n",
    "    return Mmat[:, z_kplus1.value] * alpha_temp\n",
    "\n",
    "initial_state = np.array([1, 0, 0])  # initial state of the world\n",
    "observations = np.array([State.ROOM3, State.ROOM3, State.ROOM2, State.ROOM3])  # history of observations; 0 -> room 1, 1 -> room 2, 2 -> room 3\n",
    "steps = 4\n",
    "\n",
    "alpha = initial_state * SENSOR_MAT[:, State.ROOM2.value]\n",
    "print(\"--- FORWARD STEP ---\")\n",
    "print(f\"Forward step k = 1: {alpha}\")\n",
    "forward_pass = [alpha]\n",
    "\n",
    "for i, z in enumerate(observations):\n",
    "    alpha = forward_step(alpha, SENSOR_MAT, TRANSITION_MAT, z)\n",
    "    print(f\"Forward step k = {i + 2}: {alpha}\")\n",
    "    forward_pass.append(alpha)\n",
    "\n",
    "print(\"\\n--- FILTERED STEP ---\")\n",
    "for i, a in enumerate(forward_pass):\n",
    "    filtered = a / np.sum(a)\n",
    "    print(f\"Filtered estimate k = {i + 1}: {filtered}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "687d3df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BACKWARD STEP ---\n",
      "Backward step k = 5: [1. 1. 1.]\n",
      "Backward step k = 4: [0.5  0.26 0.66]\n",
      "Backward step k = 3: [0.15   0.2004 0.1164]\n",
      "Backward step k = 2: [0.0624   0.036984 0.079344]\n",
      "Backward step k = 1: [0.037554   0.01724064 0.05109624]\n",
      "\n",
      "--- SMOOTHING STEP ---\n",
      "Smoothing step k = 0: [1. 0. 0.]\n",
      "Smoothing step k = 1: [0.         0.04924109 0.95075891]\n",
      "Smoothing step k = 2: [0.         0.09338552 0.90661448]\n",
      "Smoothing step k = 3: [0.         0.63400703 0.36599297]\n",
      "Smoothing step k = 4: [0.         0.21171513 0.78828487]\n"
     ]
    }
   ],
   "source": [
    "def backward_step(B_kplus1: np.ndarray, Mmat: np.ndarray, Tmat: np.ndarray, z_kplus1: State):\n",
    "    B_k = np.zeros_like(B_kplus1)\n",
    "    for s in State:\n",
    "        # compute B * P(x_k = s | x_k+1 = q) * P(z_k+1 | x_k+1 = q)\n",
    "        # compute for all q at once\n",
    "        B_k[s.value] += np.sum(B_kplus1 * Tmat[:, s.value] * Mmat[:, z_kplus1.value])\n",
    "    return B_k\n",
    "\n",
    "B_last = np.array([1.0, 1.0, 1.0])\n",
    "observations = np.array([State.ROOM2, State.ROOM3, State.ROOM3, State.ROOM2, State.ROOM3])\n",
    "print(f\"--- BACKWARD STEP ---\")\n",
    "print(f\"Backward step k = 5: {B_last}\")\n",
    "backward_pass = [B_last]\n",
    "\n",
    "for i in range(4,0,-1): # iterate backwards\n",
    "    B_last = backward_step(B_last, SENSOR_MAT, TRANSITION_MAT, observations[i])\n",
    "    print(f\"Backward step k = {i}: {B_last}\")\n",
    "    backward_pass.append(B_last)\n",
    "\n",
    "# Smoothing step with forward and backward\n",
    "print(f\"\\n--- SMOOTHING STEP ---\")\n",
    "for i, (fwd, bwd) in enumerate(zip(forward_pass, backward_pass[::-1])):\n",
    "    numerator = fwd * bwd\n",
    "    print(f\"Smoothing step k = {i}: {numerator/sum(numerator)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
